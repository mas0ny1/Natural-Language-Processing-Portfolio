{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91050ccd-8ed6-427a-ab15-0af52160b40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     filename  \\\n",
      "0   1_Dataset Description.txt   \n",
      "1             ABCE1-plain.txt   \n",
      "2             ABCE2-plain.txt   \n",
      "3             ABCE3-plain.txt   \n",
      "4             ABCE4-plain.txt   \n",
      "5            ABCNE1-plain.txt   \n",
      "6            ABCNE2-plain.txt   \n",
      "7             COME1-plain.txt   \n",
      "8             COME2-plain.txt   \n",
      "9             COME3-plain.txt   \n",
      "10            COME4-plain.txt   \n",
      "11            COME5-plain.txt   \n",
      "12            COME6-plain.txt   \n",
      "13            COME7-plain.txt   \n",
      "14            COME8-plain.txt   \n",
      "15           COMNE1-plain.txt   \n",
      "16           COMNE2-plain.txt   \n",
      "17           COMNE3-plain.txt   \n",
      "18           COMNE4-plain.txt   \n",
      "19           COMNE5-plain.txt   \n",
      "20           COMNE6-plain.txt   \n",
      "21           COMNE7-plain.txt   \n",
      "22             NAT1-plain.txt   \n",
      "23             NAT2-plain.txt   \n",
      "24             NAT3-plain.txt   \n",
      "25             NAT4-plain.txt   \n",
      "26             NAT5-plain.txt   \n",
      "27             NAT6-plain.txt   \n",
      "28             NAT7-plain.txt   \n",
      "29             NAT8-plain.txt   \n",
      "\n",
      "                                              content  \n",
      "0   Name\\n\\nAustralian Radio Talkback\\n\\nDescripti...  \n",
      "1    Thanks for that John Hall now John Hall will ...  \n",
      "2    Ah look l Les Pete.\\n.\\n Simon.\\n G'day Peto....  \n",
      "3    If you haven't been with us before this how i...  \n",
      "4    Uh blue-tongues'd be  unlikely to eat them be...  \n",
      "5    A very good afternoon to you Roly.\\n Good aft...  \n",
      "6    And Greg Kerrin is my guest. Hello Greg.\\n G'...  \n",
      "7    Good morning and welcome to another Two G B w...  \n",
      "8    Good morning everyone and welcome to a very f...  \n",
      "9    The doctor is in the lines are open one-three...  \n",
      "10   Morning Mark.\\n\\n Uh uh good morning John. Um...  \n",
      "11   Here's Sharina's Saturday Nights the positive...  \n",
      "12   Where we are talking about how long it takes ...  \n",
      "13   Program G P Dr Sally Cockburn good morning.\\n...  \n",
      "14   Mix one-oh-six-point-five We Did It All For L...  \n",
      "15   Freo Dockers skipper there Peter Bell hello e...  \n",
      "16   Good afternoon Howard Sattler with you welcom...  \n",
      "17   We are Talking Real Estate on eight-eighty-tw...  \n",
      "18   Thank you Len and a very good morning to a ra...  \n",
      "19   Lawyer Bob on the job merry Christmas.\\n Merr...  \n",
      "20   Well the wait ended for year twelve students ...  \n",
      "21   Been to the city lately tried to find a park ...  \n",
      "22   One-eight-hundred-eight-oh-two-three-four-one...  \n",
      "23   And speaking of welcomes and people we love R...  \n",
      "24   Good morning how are you.\\n Ih is it true you...  \n",
      "25   Eighteen minutes past ten eighteen past nine ...  \n",
      "26   So now it's welcome first to our expert panel...  \n",
      "27   you're with Mel in the morning it's fourteen ...  \n",
      "28   Five A M in New York hey. There's gotta be  s...  \n",
      "29   Hello and welcome to the Chatroom with Gaby t...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Example usage\n",
    "folder_path = 'AT1 dataset_AusRadioTalkback'\n",
    "data = []\n",
    "\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            data.append({'filename': filename, 'content': content})\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6caa58a6-a26b-4a37-a385-70803bef5cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Modified code from Lab 2 Part 2\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class TextPreprocessor:\n",
    "    def __init__(self, custom_punctuation=None, custom_stopwords=None):\n",
    "        self.punctuation = string.punctuation\n",
    "        if custom_punctuation:\n",
    "            self.punctuation += custom_punctuation\n",
    "\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        if custom_stopwords:\n",
    "            self.stop_words.update(custom_stopwords)\n",
    "\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def remove_punctuation(self, text):\n",
    "        return ''.join([char for char in text if char not in self.punctuation])\n",
    "\n",
    "    def add_space_after_parenthesis(self, text):\n",
    "        return re.sub(r'\\)', ') ', text)\n",
    "\n",
    "    def hyphen_to_space(self, text):\n",
    "        return re.sub(r'\\-', ' ', text)\n",
    "\n",
    "    def to_lowercase(self, text):\n",
    "        return text.lower()\n",
    "\n",
    "    def remove_stopwords(self, text):\n",
    "        words = word_tokenize(text)\n",
    "        return ' '.join([word for word in words if word not in self.stop_words])\n",
    "        \n",
    "    def stem_words(self, text):\n",
    "        words = word_tokenize(text)\n",
    "        return ' '.join([self.stemmer.stem(word) for word in words])\n",
    "\n",
    "    #Order matters - how you call these methods is how the text will be processed step-by-step\n",
    "    def preprocess(self, text):\n",
    "        text = self.add_space_after_parenthesis(text)\n",
    "        text = self.hyphen_to_space(text)\n",
    "        text = self.remove_punctuation(text)\n",
    "        text = self.to_lowercase(text)\n",
    "        text = self.remove_stopwords(text)\n",
    "        text = self.stem_words(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f97037d7-2430-459a-aaca-d5933f404680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     filename  \\\n",
      "0   1_Dataset Description.txt   \n",
      "1             ABCE1-plain.txt   \n",
      "2             ABCE2-plain.txt   \n",
      "3             ABCE3-plain.txt   \n",
      "4             ABCE4-plain.txt   \n",
      "5            ABCNE1-plain.txt   \n",
      "6            ABCNE2-plain.txt   \n",
      "7             COME1-plain.txt   \n",
      "8             COME2-plain.txt   \n",
      "9             COME3-plain.txt   \n",
      "10            COME4-plain.txt   \n",
      "11            COME5-plain.txt   \n",
      "12            COME6-plain.txt   \n",
      "13            COME7-plain.txt   \n",
      "14            COME8-plain.txt   \n",
      "15           COMNE1-plain.txt   \n",
      "16           COMNE2-plain.txt   \n",
      "17           COMNE3-plain.txt   \n",
      "18           COMNE4-plain.txt   \n",
      "19           COMNE5-plain.txt   \n",
      "20           COMNE6-plain.txt   \n",
      "21           COMNE7-plain.txt   \n",
      "22             NAT1-plain.txt   \n",
      "23             NAT2-plain.txt   \n",
      "24             NAT3-plain.txt   \n",
      "25             NAT4-plain.txt   \n",
      "26             NAT5-plain.txt   \n",
      "27             NAT6-plain.txt   \n",
      "28             NAT7-plain.txt   \n",
      "29             NAT8-plain.txt   \n",
      "\n",
      "                                              content  \n",
      "0   Name\\n\\nAustralian Radio Talkback\\n\\nDescripti...  \n",
      "1    Thanks for that John Hall now John Hall will ...  \n",
      "2    Ah look l Les Pete.\\n.\\n Simon.\\n G'day Peto....  \n",
      "3    If you haven't been with us before this how i...  \n",
      "4    Uh blue-tongues'd be  unlikely to eat them be...  \n",
      "5    A very good afternoon to you Roly.\\n Good aft...  \n",
      "6    And Greg Kerrin is my guest. Hello Greg.\\n G'...  \n",
      "7    Good morning and welcome to another Two G B w...  \n",
      "8    Good morning everyone and welcome to a very f...  \n",
      "9    The doctor is in the lines are open one-three...  \n",
      "10   Morning Mark.\\n\\n Uh uh good morning John. Um...  \n",
      "11   Here's Sharina's Saturday Nights the positive...  \n",
      "12   Where we are talking about how long it takes ...  \n",
      "13   Program G P Dr Sally Cockburn good morning.\\n...  \n",
      "14   Mix one-oh-six-point-five We Did It All For L...  \n",
      "15   Freo Dockers skipper there Peter Bell hello e...  \n",
      "16   Good afternoon Howard Sattler with you welcom...  \n",
      "17   We are Talking Real Estate on eight-eighty-tw...  \n",
      "18   Thank you Len and a very good morning to a ra...  \n",
      "19   Lawyer Bob on the job merry Christmas.\\n Merr...  \n",
      "20   Well the wait ended for year twelve students ...  \n",
      "21   Been to the city lately tried to find a park ...  \n",
      "22   One-eight-hundred-eight-oh-two-three-four-one...  \n",
      "23   And speaking of welcomes and people we love R...  \n",
      "24   Good morning how are you.\\n Ih is it true you...  \n",
      "25   Eighteen minutes past ten eighteen past nine ...  \n",
      "26   So now it's welcome first to our expert panel...  \n",
      "27   you're with Mel in the morning it's fourteen ...  \n",
      "28   Five A M in New York hey. There's gotta be  s...  \n",
      "29   Hello and welcome to the Chatroom with Gaby t...  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b78ceda5-9f4c-4ecc-8552-29ff24010dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row, index in df.iterrows():\n",
    "    #print(df.iloc[row]['content'])\n",
    "    pass\n",
    "\n",
    "    #overwrite the content of the row with a tokenised version I think\n",
    "    #Lab 2 Part 2 DELETEE\n",
    "#https://colab.research.google.com/drive/1yM9TayztqQw9Z7gzcS4fnUoj5ssDd84q?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68bed807-7553-400d-bb85-441385982f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove first entry (the dataset description)\n",
    "df = df.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ecff226-9da6-454a-ac6f-5b653577753a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABCE1-plain.txt</td>\n",
       "      <td>Thanks for that John Hall now John Hall will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABCE2-plain.txt</td>\n",
       "      <td>Ah look l Les Pete.\\n.\\n Simon.\\n G'day Peto....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABCE3-plain.txt</td>\n",
       "      <td>If you haven't been with us before this how i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABCE4-plain.txt</td>\n",
       "      <td>Uh blue-tongues'd be  unlikely to eat them be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABCNE1-plain.txt</td>\n",
       "      <td>A very good afternoon to you Roly.\\n Good aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABCNE2-plain.txt</td>\n",
       "      <td>And Greg Kerrin is my guest. Hello Greg.\\n G'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COME1-plain.txt</td>\n",
       "      <td>Good morning and welcome to another Two G B w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COME2-plain.txt</td>\n",
       "      <td>Good morning everyone and welcome to a very f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COME3-plain.txt</td>\n",
       "      <td>The doctor is in the lines are open one-three...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>COME4-plain.txt</td>\n",
       "      <td>Morning Mark.\\n\\n Uh uh good morning John. Um...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>COME5-plain.txt</td>\n",
       "      <td>Here's Sharina's Saturday Nights the positive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>COME6-plain.txt</td>\n",
       "      <td>Where we are talking about how long it takes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>COME7-plain.txt</td>\n",
       "      <td>Program G P Dr Sally Cockburn good morning.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>COME8-plain.txt</td>\n",
       "      <td>Mix one-oh-six-point-five We Did It All For L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>COMNE1-plain.txt</td>\n",
       "      <td>Freo Dockers skipper there Peter Bell hello e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>COMNE2-plain.txt</td>\n",
       "      <td>Good afternoon Howard Sattler with you welcom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>COMNE3-plain.txt</td>\n",
       "      <td>We are Talking Real Estate on eight-eighty-tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>COMNE4-plain.txt</td>\n",
       "      <td>Thank you Len and a very good morning to a ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>COMNE5-plain.txt</td>\n",
       "      <td>Lawyer Bob on the job merry Christmas.\\n Merr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>COMNE6-plain.txt</td>\n",
       "      <td>Well the wait ended for year twelve students ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>COMNE7-plain.txt</td>\n",
       "      <td>Been to the city lately tried to find a park ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NAT1-plain.txt</td>\n",
       "      <td>One-eight-hundred-eight-oh-two-three-four-one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NAT2-plain.txt</td>\n",
       "      <td>And speaking of welcomes and people we love R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NAT3-plain.txt</td>\n",
       "      <td>Good morning how are you.\\n Ih is it true you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NAT4-plain.txt</td>\n",
       "      <td>Eighteen minutes past ten eighteen past nine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NAT5-plain.txt</td>\n",
       "      <td>So now it's welcome first to our expert panel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NAT6-plain.txt</td>\n",
       "      <td>you're with Mel in the morning it's fourteen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NAT7-plain.txt</td>\n",
       "      <td>Five A M in New York hey. There's gotta be  s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NAT8-plain.txt</td>\n",
       "      <td>Hello and welcome to the Chatroom with Gaby t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename                                            content\n",
       "1    ABCE1-plain.txt   Thanks for that John Hall now John Hall will ...\n",
       "2    ABCE2-plain.txt   Ah look l Les Pete.\\n.\\n Simon.\\n G'day Peto....\n",
       "3    ABCE3-plain.txt   If you haven't been with us before this how i...\n",
       "4    ABCE4-plain.txt   Uh blue-tongues'd be  unlikely to eat them be...\n",
       "5   ABCNE1-plain.txt   A very good afternoon to you Roly.\\n Good aft...\n",
       "6   ABCNE2-plain.txt   And Greg Kerrin is my guest. Hello Greg.\\n G'...\n",
       "7    COME1-plain.txt   Good morning and welcome to another Two G B w...\n",
       "8    COME2-plain.txt   Good morning everyone and welcome to a very f...\n",
       "9    COME3-plain.txt   The doctor is in the lines are open one-three...\n",
       "10   COME4-plain.txt   Morning Mark.\\n\\n Uh uh good morning John. Um...\n",
       "11   COME5-plain.txt   Here's Sharina's Saturday Nights the positive...\n",
       "12   COME6-plain.txt   Where we are talking about how long it takes ...\n",
       "13   COME7-plain.txt   Program G P Dr Sally Cockburn good morning.\\n...\n",
       "14   COME8-plain.txt   Mix one-oh-six-point-five We Did It All For L...\n",
       "15  COMNE1-plain.txt   Freo Dockers skipper there Peter Bell hello e...\n",
       "16  COMNE2-plain.txt   Good afternoon Howard Sattler with you welcom...\n",
       "17  COMNE3-plain.txt   We are Talking Real Estate on eight-eighty-tw...\n",
       "18  COMNE4-plain.txt   Thank you Len and a very good morning to a ra...\n",
       "19  COMNE5-plain.txt   Lawyer Bob on the job merry Christmas.\\n Merr...\n",
       "20  COMNE6-plain.txt   Well the wait ended for year twelve students ...\n",
       "21  COMNE7-plain.txt   Been to the city lately tried to find a park ...\n",
       "22    NAT1-plain.txt   One-eight-hundred-eight-oh-two-three-four-one...\n",
       "23    NAT2-plain.txt   And speaking of welcomes and people we love R...\n",
       "24    NAT3-plain.txt   Good morning how are you.\\n Ih is it true you...\n",
       "25    NAT4-plain.txt   Eighteen minutes past ten eighteen past nine ...\n",
       "26    NAT5-plain.txt   So now it's welcome first to our expert panel...\n",
       "27    NAT6-plain.txt   you're with Mel in the morning it's fourteen ...\n",
       "28    NAT7-plain.txt   Five A M in New York hey. There's gotta be  s...\n",
       "29    NAT8-plain.txt   Hello and welcome to the Chatroom with Gaby t..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "587a3f8c-a088-404a-9de7-541114a9c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code that combines all the different df rows based on filename into 1 long string grouped by radio Station\n",
    "\n",
    "#Create prefix column using regex (take characters from beginning of filename, until you hit a number)\n",
    "df['prefix'] = df['filename'].apply(lambda x: re.match(r'^[A-Z]+', x).group())\n",
    "\n",
    "#Group by prefix\n",
    "df_combined = df.groupby('prefix')['content'].apply(' '.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c03a74a1-bfb5-4bd5-bc3e-e9883d031626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Thanks for that John Hall now John Hall will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABCNE</td>\n",
       "      <td>A very good afternoon to you Roly.\\n Good aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COME</td>\n",
       "      <td>Good morning and welcome to another Two G B w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COMNE</td>\n",
       "      <td>Freo Dockers skipper there Peter Bell hello e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NAT</td>\n",
       "      <td>One-eight-hundred-eight-oh-two-three-four-one...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prefix                                            content\n",
       "0   ABCE   Thanks for that John Hall now John Hall will ...\n",
       "1  ABCNE   A very good afternoon to you Roly.\\n Good aft...\n",
       "2   COME   Good morning and welcome to another Two G B w...\n",
       "3  COMNE   Freo Dockers skipper there Peter Bell hello e...\n",
       "4    NAT   One-eight-hundred-eight-oh-two-three-four-one..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12d64759-c9cd-4234-a43b-b9d1000c06e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom punctuation and stopwords\n",
    "custom_punctuation = \"''\"\"…\"\"...\"\"``\" '\"' '-'  # Add any custom punctuation marks here\n",
    "custom_stopwords = []  # Add any custom stopwords here\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = TextPreprocessor(custom_punctuation, custom_stopwords)\n",
    "\n",
    "# Preprocess the text\n",
    "#preprocessed_text = preprocessor.preprocess(article_text)\n",
    "\n",
    "preprocessed = df_combined.iloc[0]['content']\n",
    "# Preprocess the text\n",
    "processed = preprocessor.preprocess(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "361da532-b16b-40fe-a229-15874bb7780a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 most frequent words:\n",
      "uh: 580\n",
      "um: 286\n",
      "yeah: 232\n",
      "well: 200\n",
      "like: 167\n",
      "ye: 166\n",
      "that: 146\n",
      "get: 139\n",
      "oh: 133\n",
      "think: 130\n",
      "one: 123\n",
      "good: 118\n",
      "got: 111\n",
      "go: 109\n",
      "would: 99\n",
      "realli: 95\n",
      "sort: 94\n",
      "look: 85\n",
      "thank: 84\n",
      "theyr: 82\n"
     ]
    }
   ],
   "source": [
    "# Get word frequencies\n",
    "def get_word_frequencies(text, top_n=10):\n",
    "    words = word_tokenize(text)\n",
    "    word_freq = Counter(words)\n",
    "    return word_freq.most_common(top_n)\n",
    "\n",
    "word_freq = get_word_frequencies(processed, top_n=20)\n",
    "\n",
    "print(\"\\nTop 20 most frequent words:\")\n",
    "for word, count in word_freq:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3382ae9b-4818-49b5-82e3-3bc2a9351cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 most frequent words:\n",
      "that: 146\n",
      "think: 130\n",
      "one: 123\n",
      "good: 118\n",
      "got: 111\n",
      "go: 109\n",
      "would: 99\n",
      "realli: 95\n",
      "sort: 94\n",
      "look: 85\n",
      "im: 77\n",
      "know: 76\n",
      "two: 74\n",
      "dont: 73\n",
      "ih: 72\n",
      "say: 71\n",
      "book: 70\n",
      "want: 69\n",
      "see: 66\n",
      "bit: 66\n",
      "actual: 66\n",
      "mm: 62\n",
      "id: 61\n",
      "yknow: 59\n",
      "thing: 59\n",
      "right: 56\n",
      "there: 56\n",
      "use: 55\n",
      "littl: 53\n",
      "time: 53\n",
      "plant: 51\n",
      "put: 49\n",
      "year: 49\n",
      "call: 48\n",
      "come: 48\n",
      "thought: 48\n",
      "your: 48\n",
      "take: 47\n",
      "youv: 47\n",
      "read: 47\n",
      "could: 46\n",
      "much: 45\n",
      "paint: 44\n",
      "someth: 42\n",
      "three: 41\n",
      "love: 41\n",
      "old: 40\n",
      "lot: 39\n",
      "quit: 39\n",
      "also: 38\n"
     ]
    }
   ],
   "source": [
    "# Custom punctuation and stopwords\n",
    "custom_punctuation = \"''\"\"…\"\"...\"\"``\" '\"' '-'  # Add any custom punctuation marks here\n",
    "custom_stopwords = [\"uh\", \"well\", \"um\", \"yes\", \"yeah\", \"theyre\", \"get\", \"that\", \"like\", \"oh\", \"thank\", \"ive\", \"yep\", \"c\", \"okay\", \"your\", \"you're\"]  # Add any custom stopwords here\n",
    "#yes and theyre are the full non-stemmed versions of \"ye\" and 'theyr\"\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = TextPreprocessor(custom_punctuation, custom_stopwords)\n",
    "\n",
    "# Preprocess the text\n",
    "#preprocessed_text = preprocessor.preprocess(article_text)\n",
    "\n",
    "preprocessed = df_combined.iloc[0]['content']\n",
    "# Preprocess the text\n",
    "processed = preprocessor.preprocess(preprocessed)\n",
    "\n",
    "word_freq = get_word_frequencies(processed, top_n=50)\n",
    "\n",
    "print(\"\\nTop 20 most frequent words:\")\n",
    "for word, count in word_freq:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81df0a-3f76-4534-a89b-f73c83aef881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
